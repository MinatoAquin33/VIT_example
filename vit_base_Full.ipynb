{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5842b58b-a2a7-48ad-aab2-3ac4993638b6",
   "metadata": {},
   "source": [
    "# 测试base完整模型的性能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a8376-258b-4d9c-aebe-d809bb4d4148",
   "metadata": {},
   "source": [
    "## 载入数据和模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59517293-a5c5-42eb-b977-0eb21e37a26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbc1dfe2e214979924ca703c2635185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/5380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b53e3862e84cd5af68461128665317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(path=\"imagefolder\", data_dir=\"E:/jupyter/VIT_example/dataset/hfdataset_Mini\") #路径不能有中文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b04c156f-c72f-46c2-9bab-4f8ff01e9d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f17ca44b20642f8bdbf2e7eb0dff7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9722c0b19554434a5277d95cd49c422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8236e6c182743b4acfc65545cbd593a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12007c1e071645448e1954c2e6070f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Original column name label not in the dataset. Current columns in the dataset: ['image', 'labels']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 51\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: accuracy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m: f1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: precision[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m: recall[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     47\u001b[0m     }\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m---> 51\u001b[0m     dataset[split] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename_column\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 将 'label' 特征名改为 'labels'\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:593\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    592\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 593\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\fingerprint.py:482\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:2208\u001b[0m, in \u001b[0;36mDataset.rename_column\u001b[1;34m(self, original_column_name, new_column_name, new_fingerprint)\u001b[0m\n\u001b[0;32m   2206\u001b[0m dataset \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   2207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m original_column_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names:\n\u001b[1;32m-> 2208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2209\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal column name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_column_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in the dataset. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2210\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2211\u001b[0m     )\n\u001b[0;32m   2212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_column_name \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names:\n\u001b[0;32m   2213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2214\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew column name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_column_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already in the dataset. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2215\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease choose a column name which is not already in the dataset. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2216\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2217\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Original column name label not in the dataset. Current columns in the dataset: ['image', 'labels']"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoImageProcessor\n",
    "\n",
    "# 加载图像处理器\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "def transforms(examples):\n",
    "    images = [img.convert(\"RGB\").resize((224, 224)) for img in examples[\"image\"]]  # 图片被转换为RGB通道，同时缩放至224*224\n",
    "    \n",
    "    examples[\"pixel_values\"] = image_processor(images, return_tensors=\"pt\")[\"pixel_values\"] # 使用image_processor处理图像，生成pixel_values（张量图像）\n",
    "    return examples\n",
    "\n",
    "dataset.set_transform(transforms)\n",
    "dataset['train'][0].keys()\n",
    "\n",
    "import torch\n",
    "\n",
    "def collate_fn(batch): # batch应包含pixel_values和labels\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]), # 返回堆叠的图像张量\n",
    "        'labels': torch.tensor([x['labels'] for x in batch]) # 返回堆叠的标签张量\n",
    "    }\n",
    "\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    # 计算预测结果\n",
    "    predictions = np.argmax(p.predictions, axis=1)\n",
    "\n",
    "    # 计算各个指标\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=p.label_ids)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=p.label_ids, average='weighted')\n",
    "    precision = precision_metric.compute(predictions=predictions, references=p.label_ids, average='weighted')\n",
    "    recall = recall_metric.compute(predictions=predictions, references=p.label_ids, average='weighted')\n",
    "\n",
    "    # 输出结果\n",
    "    return {\n",
    "        'accuracy': accuracy['accuracy'],\n",
    "        'f1': f1['f1'],\n",
    "        'precision': precision['precision'],\n",
    "        'recall': recall['recall']\n",
    "    }\n",
    "\n",
    "\n",
    "for split in dataset:\n",
    "    dataset[split] = dataset[split].rename_column('label', 'labels') # 将 'label' 特征名改为 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afdfb1eb-0b2a-4019-8d44-797792783668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "model_name = 'google/vit-base-patch16-224-in21k' # 指定VIT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2074e15a-2ddd-46aa-9832-7d449acb51a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTForImageClassification.from_pretrained(\"./vit-base-covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "788b0823-2503-4b92-bdb7-693d537dc229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./vit-base-covid\", # 模型保存的目录\n",
    "  per_device_train_batch_size=16, # 越大模型越稳定但需要消耗更大显存\n",
    "  evaluation_strategy=\"steps\", #模型评估策略，steps表示每过一定次数评估一次模型\n",
    "  num_train_epochs=100, #训练轮数\n",
    "  fp16=True, #半精度浮点，可减少内存占用，需要设备支持\n",
    "  save_steps=100, #多少步保存一次模型\n",
    "  eval_steps=100, #多少步评估一次模型\n",
    "  logging_steps=3, #多少步评估一次日志\n",
    "  learning_rate=2e-4, #学习率 越低越容易过拟合，越高收敛越慢\n",
    "  save_total_limit=10, #保存的模型总数\n",
    "  remove_unused_columns=False, #删除未使用列，减少内存消耗\n",
    "  push_to_hub=False, #是否将模型发布到hf社区\n",
    "  report_to='tensorboard', #日志的报告地\n",
    "  load_best_model_at_end=True, #是否自动加载最优模型\n",
    "  ignore_data_skip=True #从断点继续训练模型\n",
    ")\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=image_processor,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c7f68-fa41-463d-a736-91cc340b7d2b",
   "metadata": {},
   "source": [
    "## 基准测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8702657b-4ce2-4d7c-bed8-4276a5e814ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  eval_accuracy           =     0.8301\n",
      "  eval_f1                 =     0.8323\n",
      "  eval_loss               =     0.6882\n",
      "  eval_precision          =     0.8767\n",
      "  eval_recall             =     0.8301\n",
      "  eval_runtime            = 0:00:11.53\n",
      "  eval_samples_per_second =      27.04\n",
      "  eval_steps_per_second   =       3.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\w1586\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(dataset['test'])\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59a134-265f-47b6-a628-7be1a91ed17c",
   "metadata": {},
   "source": [
    "## 外部验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a4c155-e457-442f-8df0-d142ee58394f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08059d3ec7f48e28c92b323a6dc7c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "Outerdataset = load_dataset(path=\"imagefolder\", data_dir=\"E:/jupyter/VIT_example/dataset/Outerdataset\") #路径不能有中文\n",
    "Outerdataset.set_transform(transforms)\n",
    "Outerdataset['test'][0].keys()\n",
    "for split in Outerdataset:\n",
    "    Outerdataset[split] = Outerdataset[split].rename_column('label', 'labels') # 将 'label' 特征名改为 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee1886-152d-4740-9d5c-520c48f9a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(Outerdataset[\"test\"])\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f711c168-6bf2-437d-8bef-0715af6b3910",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 对特定图片进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d771c73c-60cf-4394-957a-5ab01359098b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1458x1303>,\n",
       " 'labels': 0,\n",
       " 'pixel_values': tensor([[[-0.6235, -0.6157, -0.6078,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          [-0.5843, -0.5765, -0.5686,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          [-0.5608, -0.5686, -0.5608,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          ...,\n",
       "          [-0.1059, -0.0824, -0.0431,  ..., -0.3333, -0.3647, -0.3804],\n",
       "          [-0.1137, -0.0824, -0.0353,  ..., -0.3412, -0.3647, -0.3882],\n",
       "          [-0.1137, -0.0824, -0.0353,  ..., -0.3490, -0.3725, -0.3882]],\n",
       " \n",
       "         [[-0.6235, -0.6157, -0.6078,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          [-0.5843, -0.5765, -0.5686,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          [-0.5608, -0.5686, -0.5608,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          ...,\n",
       "          [-0.1059, -0.0824, -0.0431,  ..., -0.3333, -0.3647, -0.3804],\n",
       "          [-0.1137, -0.0824, -0.0353,  ..., -0.3412, -0.3647, -0.3882],\n",
       "          [-0.1137, -0.0824, -0.0353,  ..., -0.3490, -0.3725, -0.3882]],\n",
       " \n",
       "         [[-0.6235, -0.6157, -0.6078,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          [-0.5843, -0.5765, -0.5686,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          [-0.5608, -0.5686, -0.5608,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          ...,\n",
       "          [-0.1059, -0.0824, -0.0431,  ..., -0.3333, -0.3647, -0.3804],\n",
       "          [-0.1137, -0.0824, -0.0353,  ..., -0.3412, -0.3647, -0.3882],\n",
       "          [-0.1137, -0.0824, -0.0353,  ..., -0.3490, -0.3725, -0.3882]]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num=1\n",
    "image=dataset[\"test\"][num][\"image\"]\n",
    "dataset[\"test\"][num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc8331c9-d1e0-4bcb-a8b2-759f0522f46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9979442954063416, 'label': 'Covid'},\n",
       " {'score': 0.0007841807091608644, 'label': 'Lung Opacity'},\n",
       " {'score': 0.0006628449191339314, 'label': 'Normal'},\n",
       " {'score': 0.0006086361245252192, 'label': 'Viral Pneumonia'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"image-classification\", model='./vit-base-covid/' )\n",
    "classifier(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16379da-d0ad-4ea9-8a4f-6ac6d49a2512",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 进行Covid与非Covid的二分类预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5c9017f-ed6e-4575-af82-f00f4b4a6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    # 将预测结果中的所有非0（非Covid）标签转换为1\n",
    "    predictions = np.argmax(p.predictions, axis=1)\n",
    "    binary_predictions = np.where(predictions == 0, 0, 1)\n",
    "\n",
    "    # 将真实标签中的所有非0（非Covid）标签转换为1\n",
    "    binary_references = np.where(p.label_ids == 0, 0, 1)\n",
    "\n",
    "    # 计算二分类的各个指标\n",
    "    accuracy = accuracy_metric.compute(predictions=binary_predictions, references=binary_references)['accuracy']\n",
    "    f1 = f1_metric.compute(predictions=binary_predictions, references=binary_references, average='binary')['f1']\n",
    "    precision = precision_metric.compute(predictions=binary_predictions, references=binary_references, average='binary')['precision']\n",
    "    recall = recall_metric.compute(predictions=binary_predictions, references=binary_references, average='binary')['recall']\n",
    "\n",
    "    # 返回计算的指标\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./vit-simple-covid\", # 模型保存的目录\n",
    "  per_device_train_batch_size=16, # 越大模型越稳定但需要消耗更大显存\n",
    "  evaluation_strategy=\"steps\", #模型评估策略，steps表示每过一定次数评估一次模型\n",
    "  num_train_epochs=100, #训练轮数\n",
    "  fp16=True, #半精度浮点，可减少内存占用，需要设备支持\n",
    "  save_steps=100, #多少步保存一次模型\n",
    "  eval_steps=100, #多少步评估一次模型\n",
    "  logging_steps=3, #多少步评估一次日志\n",
    "  learning_rate=2e-4, #学习率 越低越容易过拟合，越高收敛越慢\n",
    "  save_total_limit=10, #保存的模型总数\n",
    "  remove_unused_columns=False, #删除未使用列，减少内存消耗\n",
    "  push_to_hub=False, #是否将模型发布到hf社区\n",
    "  report_to='tensorboard', #日志的报告地\n",
    "  load_best_model_at_end=True, #是否自动加载最优模型\n",
    "  ignore_data_skip=True #从断点继续训练模型\n",
    ")\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=image_processor,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15483d8a-46d5-4a3c-b550-2744a592d590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 25:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mlog_metrics(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics)\n\u001b[0;32m      3\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_metrics(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2932\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   2929\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   2931\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 2932\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2933\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2935\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   2936\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   2937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2940\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2942\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   2943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:3220\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3216\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[0;32m   3217\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[0;32m   3218\u001b[0m         )\n\u001b[0;32m   3219\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3220\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3222\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_metrics\u001b[39m(p):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# 将预测结果中的所有非0（非Covid）标签转换为1\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39margmax(p\u001b[38;5;241m.\u001b[39mpredictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m     binary_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(predictions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# 将真实标签中的所有非0（非Covid）标签转换为1\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(dataset['test'])\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34c39f-b59b-4a7b-bf4c-0b2def8990eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
