{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5842b58b-a2a7-48ad-aab2-3ac4993638b6",
   "metadata": {},
   "source": [
    "# 测试Large完整模型的性能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a8376-258b-4d9c-aebe-d809bb4d4148",
   "metadata": {},
   "source": [
    "## 载入数据和模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59517293-a5c5-42eb-b977-0eb21e37a26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b4ad60316f40b5b68c2c258a6ed54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/3768 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75794b3626bf4969991c18738aaff89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(path=\"imagefolder\", data_dir=\"E:/jupyter/VIT_example/dataset/hfdataset_Mini\") #路径不能有中文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b04c156f-c72f-46c2-9bab-4f8ff01e9d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoImageProcessor\n",
    "\n",
    "# 加载图像处理器\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-large-patch32-384\")\n",
    "\n",
    "def transforms(examples):\n",
    "    images = [img.convert(\"RGB\").resize((384, 384)) for img in examples[\"image\"]]  # 图片被转换为RGB通道，同时缩放至224*224\n",
    "    \n",
    "    examples[\"pixel_values\"] = image_processor(images, return_tensors=\"pt\")[\"pixel_values\"] # 使用image_processor处理图像，生成pixel_values（张量图像）\n",
    "    return examples\n",
    "\n",
    "dataset.set_transform(transforms)\n",
    "dataset['train'][0].keys()\n",
    "\n",
    "import torch\n",
    "\n",
    "def collate_fn(batch): # batch应包含pixel_values和labels\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]), # 返回堆叠的图像张量\n",
    "        'labels': torch.tensor([x['labels'] for x in batch]) # 返回堆叠的标签张量\n",
    "    }\n",
    "\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    # 计算预测结果\n",
    "    predictions = np.argmax(p.predictions, axis=1)\n",
    "\n",
    "    # 计算各个指标\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=p.label_ids)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=p.label_ids, average='weighted')\n",
    "    precision = precision_metric.compute(predictions=predictions, references=p.label_ids, average='weighted')\n",
    "    recall = recall_metric.compute(predictions=predictions, references=p.label_ids, average='weighted')\n",
    "\n",
    "    # 输出结果\n",
    "    return {\n",
    "        'accuracy': accuracy['accuracy'],\n",
    "        'f1': f1['f1'],\n",
    "        'precision': precision['precision'],\n",
    "        'recall': recall['recall']\n",
    "    }\n",
    "\n",
    "\n",
    "for split in dataset:\n",
    "    dataset[split] = dataset[split].rename_column('label', 'labels') # 将 'label' 特征名改为 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afdfb1eb-0b2a-4019-8d44-797792783668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "model_name = 'google/vit-large-patch32-384' # 指定VIT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2074e15a-2ddd-46aa-9832-7d449acb51a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "model = ViTForImageClassification.from_pretrained(\"./vit-large-covid-Full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "788b0823-2503-4b92-bdb7-693d537dc229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./vit-base-covid\", # 模型保存的目录\n",
    "  per_device_train_batch_size=16, # 越大模型越稳定但需要消耗更大显存\n",
    "  evaluation_strategy=\"steps\", #模型评估策略，steps表示每过一定次数评估一次模型\n",
    "  num_train_epochs=100, #训练轮数\n",
    "  fp16=True, #半精度浮点，可减少内存占用，需要设备支持\n",
    "  save_steps=100, #多少步保存一次模型\n",
    "  eval_steps=100, #多少步评估一次模型\n",
    "  logging_steps=3, #多少步评估一次日志\n",
    "  learning_rate=1e-5, #学习率 越低越容易过拟合，越高收敛越慢\n",
    "  save_total_limit=3, #保存的模型总数\n",
    "  remove_unused_columns=False, #删除未使用列，减少内存消耗\n",
    "  push_to_hub=False, #是否将模型发布到hf社区\n",
    "  report_to='tensorboard', #日志的报告地\n",
    "  load_best_model_at_end=True, #是否自动加载最优模型\n",
    "  ignore_data_skip=True #从断点继续训练模型\n",
    ")\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=image_processor,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c7f68-fa41-463d-a736-91cc340b7d2b",
   "metadata": {},
   "source": [
    "## 基准测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8702657b-4ce2-4d7c-bed8-4276a5e814ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='241' max='202' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [202/202 00:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  eval_accuracy           =     0.9615\n",
      "  eval_f1                 =     0.9613\n",
      "  eval_loss               =       0.19\n",
      "  eval_precision          =     0.9613\n",
      "  eval_recall             =     0.9615\n",
      "  eval_runtime            = 0:00:33.31\n",
      "  eval_samples_per_second =     48.384\n",
      "  eval_steps_per_second   =      6.063\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(dataset['test'])\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59a134-265f-47b6-a628-7be1a91ed17c",
   "metadata": {},
   "source": [
    "## 外部验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12a4c155-e457-442f-8df0-d142ee58394f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac00eeb53e934324ae1bd93e2de2efdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "Outerdataset = load_dataset(path=\"imagefolder\", data_dir=\"E:/jupyter/VIT_example/dataset/Outerdataset\") #路径不能有中文\n",
    "Outerdataset.set_transform(transforms)\n",
    "# Outerdataset['test'][0].keys()\n",
    "for split in Outerdataset:\n",
    "    Outerdataset[split] = Outerdataset[split].rename_column('label', 'labels') # 将 'label' 特征名改为 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eee1886-152d-4740-9d5c-520c48f9a0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  eval_accuracy           =     0.3782\n",
      "  eval_f1                 =     0.3879\n",
      "  eval_loss               =     7.0652\n",
      "  eval_precision          =     0.4138\n",
      "  eval_recall             =     0.3782\n",
      "  eval_runtime            = 0:00:15.36\n",
      "  eval_samples_per_second =     20.306\n",
      "  eval_steps_per_second   =      2.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\w1586\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(Outerdataset[\"test\"])\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f711c168-6bf2-437d-8bef-0715af6b3910",
   "metadata": {},
   "source": [
    "## 对特定图片进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d771c73c-60cf-4394-957a-5ab01359098b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1458x1303>,\n",
       " 'labels': 0,\n",
       " 'pixel_values': tensor([[[-0.6392, -0.6314, -0.6235,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          [-0.6078, -0.6000, -0.6000,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          [-0.5922, -0.5843, -0.5765,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          ...,\n",
       "          [-0.1216, -0.0980, -0.0824,  ..., -0.3647, -0.3804, -0.3882],\n",
       "          [-0.1137, -0.0980, -0.0902,  ..., -0.3725, -0.3804, -0.3961],\n",
       "          [-0.1137, -0.0980, -0.0824,  ..., -0.3647, -0.3804, -0.3961]],\n",
       " \n",
       "         [[-0.6392, -0.6314, -0.6235,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          [-0.6078, -0.6000, -0.6000,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          [-0.5922, -0.5843, -0.5765,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          ...,\n",
       "          [-0.1216, -0.0980, -0.0824,  ..., -0.3647, -0.3804, -0.3882],\n",
       "          [-0.1137, -0.0980, -0.0902,  ..., -0.3725, -0.3804, -0.3961],\n",
       "          [-0.1137, -0.0980, -0.0824,  ..., -0.3647, -0.3804, -0.3961]],\n",
       " \n",
       "         [[-0.6392, -0.6314, -0.6235,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          [-0.6078, -0.6000, -0.6000,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          [-0.5922, -0.5843, -0.5765,  ..., -0.9843, -0.9843, -0.9843],\n",
       "          ...,\n",
       "          [-0.1216, -0.0980, -0.0824,  ..., -0.3647, -0.3804, -0.3882],\n",
       "          [-0.1137, -0.0980, -0.0902,  ..., -0.3725, -0.3804, -0.3961],\n",
       "          [-0.1137, -0.0980, -0.0824,  ..., -0.3647, -0.3804, -0.3961]]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num=1\n",
    "image=Outerdataset[\"test\"][num][\"image\"]\n",
    "Outerdataset[\"test\"][num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc8331c9-d1e0-4bcb-a8b2-759f0522f46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9999901056289673, 'label': 'Covid'},\n",
       " {'score': 6.601129825867247e-06, 'label': 'Lung Opacity'},\n",
       " {'score': 2.090611815219745e-06, 'label': 'Normal'},\n",
       " {'score': 1.2494034535848186e-06, 'label': 'Viral Pneumonia'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"image-classification\", model='./vit-large-covid-Full' )\n",
    "classifier(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16379da-d0ad-4ea9-8a4f-6ac6d49a2512",
   "metadata": {},
   "source": [
    "## 进行Covid与非Covid的二分类预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5c9017f-ed6e-4575-af82-f00f4b4a6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(p):\n",
    "    # 将预测结果中的所有非0（非Covid）标签转换为1\n",
    "    predictions = np.argmax(p.predictions, axis=1)\n",
    "    binary_predictions = np.where(predictions == 0, 0, 1)\n",
    "\n",
    "    # 将真实标签中的所有非0（非Covid）标签转换为1\n",
    "    binary_references = np.where(p.label_ids == 0, 0, 1)\n",
    "\n",
    "    # 计算二分类的各个指标\n",
    "    accuracy = accuracy_metric.compute(predictions=binary_predictions, references=binary_references)['accuracy']\n",
    "    f1 = f1_metric.compute(predictions=binary_predictions, references=binary_references, average='binary')['f1']\n",
    "    precision = precision_metric.compute(predictions=binary_predictions, references=binary_references, average='binary')['precision']\n",
    "    recall = recall_metric.compute(predictions=binary_predictions, references=binary_references, average='binary')['recall']\n",
    "\n",
    "    # 返回计算的指标\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./vit-simple-covid\", # 模型保存的目录\n",
    "  per_device_train_batch_size=16, # 越大模型越稳定但需要消耗更大显存\n",
    "  evaluation_strategy=\"steps\", #模型评估策略，steps表示每过一定次数评估一次模型\n",
    "  num_train_epochs=100, #训练轮数\n",
    "  fp16=True, #半精度浮点，可减少内存占用，需要设备支持\n",
    "  save_steps=100, #多少步保存一次模型\n",
    "  eval_steps=100, #多少步评估一次模型\n",
    "  logging_steps=3, #多少步评估一次日志\n",
    "  learning_rate=2e-4, #学习率 越低越容易过拟合，越高收敛越慢\n",
    "  save_total_limit=10, #保存的模型总数\n",
    "  remove_unused_columns=False, #删除未使用列，减少内存消耗\n",
    "  push_to_hub=False, #是否将模型发布到hf社区\n",
    "  report_to='tensorboard', #日志的报告地\n",
    "  load_best_model_at_end=True, #是否自动加载最优模型\n",
    "  ignore_data_skip=True #从断点继续训练模型\n",
    ")\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=Outerdataset[\"test\"],\n",
    "    tokenizer=image_processor,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15483d8a-46d5-4a3c-b550-2744a592d590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  eval_accuracy           =     0.9199\n",
      "  eval_f1                 =     0.9315\n",
      "  eval_loss               =     7.0652\n",
      "  eval_precision          =     0.9189\n",
      "  eval_recall             =     0.9444\n",
      "  eval_runtime            = 0:00:15.15\n",
      "  eval_samples_per_second =     20.581\n",
      "  eval_steps_per_second   =      2.573\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(Outerdataset['test'])\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
